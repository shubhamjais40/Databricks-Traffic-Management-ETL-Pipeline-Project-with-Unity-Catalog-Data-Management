{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3d929c0-f5b7-4fee-9df2-528a8b944b45",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Use catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e556fbd4-6b79-48cd-9329-f941840a5b50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"env\",defaultValue='',label='Enter the environment or catalog in lower case')\n",
    "env = dbutils.widgets.get(\"env\")\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b0cd9ec-36f7-45ee-988b-a48942df1a6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "bronze_path = spark.sql(\"\"\"describe external location bronze_db;\"\"\").select('url').collect()[0][0]\n",
    "silver_path = spark.sql(\"\"\"describe external location silver_db;\"\"\").select('url').collect()[0][0]\n",
    "gold_path = spark.sql(\"\"\"describe external location gold_db;\"\"\").select('url').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d99f08c-4636-46fd-927c-de4aca185c21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_Bronze_schema(environment,path):\n",
    "    print(f\"Using catalog {environment}\")\n",
    "    spark.sql(f\"\"\"use catalog {environment}\"\"\")\n",
    "    print(f\"creating schema for bronze\")\n",
    "    spark.sql(f\"\"\"CREATE SCHEMA IF NOT EXISTS BRONZE MANAGED LOCATION '{path}/bronze';\"\"\")\n",
    "\n",
    "def create_Silver_schema(environment,path):\n",
    "    print(f\"Using catalog {environment}\")\n",
    "    spark.sql(f\"\"\"use catalog {environment}\"\"\")\n",
    "    print(f\"creating schema for silver\")\n",
    "    spark.sql(f\"\"\"CREATE SCHEMA IF NOT EXISTS SILVER MANAGED LOCATION '{path}/silver';\"\"\")\n",
    "\n",
    "def create_Gold_schema(environment,path):\n",
    "    print(f\"Using catalog {environment}\")\n",
    "    spark.sql(f\"\"\"use catalog {environment}\"\"\")\n",
    "    print(f\"creating schema for gold\")\n",
    "    spark.sql(f\"\"\"CREATE SCHEMA IF NOT EXISTS GOLD MANAGED LOCATION '{path}/gold';\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1703c47c-9f56-4869-9ccd-5955382fa647",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_Bronze_schema(env,path=bronze_path)\n",
    "create_Silver_schema(env,path=silver_path)\n",
    "create_Gold_schema(env,path=gold_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e39bb35e-260d-4cad-89c1-4879245d5247",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Creating Bronze Layer Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb9d6b66-94c1-4a25-aa18-9ec80691bd6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def createTable_rawTraffic(environment):\n",
    "    print(f'Creating raw_Traffic table in {environment}_catalog')\n",
    "    spark.sql(f\"\"\"CREATE TABLE IF NOT EXISTS `{environment}`.`bronze`.`raw_traffic`\n",
    "                        (\n",
    "                            Record_ID INT,\n",
    "                            Count_point_id INT,\n",
    "                            Direction_of_travel VARCHAR(255),\n",
    "                            Year INT,\n",
    "                            Count_date VARCHAR(255),\n",
    "                            hour INT,\n",
    "                            Region_id INT,\n",
    "                            Region_name VARCHAR(255),\n",
    "                            Local_authority_name VARCHAR(255),\n",
    "                            Road_name VARCHAR(255),\n",
    "                            Road_Category_ID INT,\n",
    "                            Start_junction_road_name VARCHAR(255),\n",
    "                            End_junction_road_name VARCHAR(255),\n",
    "                            Latitude DOUBLE,\n",
    "                            Longitude DOUBLE,\n",
    "                            Link_length_km DOUBLE,\n",
    "                            Pedal_cycles INT,\n",
    "                            Two_wheeled_motor_vehicles INT,\n",
    "                            Cars_and_taxis INT,\n",
    "                            Buses_and_coaches INT,\n",
    "                            LGV_Type INT,\n",
    "                            HGV_Type INT,\n",
    "                            EV_Car INT,\n",
    "                            EV_Bike INT,\n",
    "                            Extract_Time TIMESTAMP\n",
    "                    );\"\"\")\n",
    "    \n",
    "    print(\"************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b94a43d-9b71-449f-9615-926c2c981dcc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def createTable_rawRoad(environment):\n",
    "    print(f'Creating raw_roads table in {environment}_catalog')\n",
    "    spark.sql(f\"\"\"CREATE TABLE IF NOT EXISTS `{environment}`.`bronze`.`raw_roads`\n",
    "                        (\n",
    "                            Road_ID INT,\n",
    "                            Road_Category_Id INT,\n",
    "                            Road_Category VARCHAR(255),\n",
    "                            Region_ID INT,\n",
    "                            Region_Name VARCHAR(255),\n",
    "                            Total_Link_Length_Km DOUBLE,\n",
    "                            Total_Link_Length_Miles DOUBLE,\n",
    "                            All_Motor_Vehicles DOUBLE\n",
    "                    );\"\"\")\n",
    "    \n",
    "    print(\"************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf70cc07-f53d-40da-96c5-12852af586ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "createTable_rawRoad(env)\n",
    "createTable_rawTraffic(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea97fb07-94a3-42ea-847f-39c75ea91028",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def reset_catalog_schemas():\n",
    "\n",
    "    spark.sql(\"\"\"drop schema `bronze`;\"\"\")\n",
    "    spark.sql(\"\"\"drop schema `silver`;\"\"\")\n",
    "    spark.sql(\"\"\"drop schema `gold`;\"\"\")\n",
    "    return \"Dropped all schemas\""
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Project Setup",
   "widgets": {
    "env": {
     "currentValue": "devops_databricks",
     "nuid": "cb16879a-189d-42d6-97ec-b5561d3b6ba6",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Enter the environment or catalog in lower case",
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Enter the environment or catalog in lower case",
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
